{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import cv2\n",
    "class BackgroundModel:\n",
    "    def __init__(self, width, height, num_clusters=5, manhattan_threshold=20, L=512):\n",
    "        self.width = width\n",
    "        self.height = height\n",
    "        self.num_clusters = num_clusters\n",
    "        self.manhattan_threshold = manhattan_threshold\n",
    "        self.L = L\n",
    "\n",
    "        # Initialize clusters: (weight, Y, Cb, Cr)\n",
    "        self.clusters = np.zeros((height, width, num_clusters, 4))  # (weight, Y, Cb, Cr)\n",
    "\n",
    "    def manhattan_distance(self, centroid, pixel):\n",
    "        \"\"\"Compute Manhattan distance between a centroid and a pixel.\"\"\"\n",
    "        Y, Cb, Cr = centroid[1:]  # Centroid's components\n",
    "        p_Y, p_Cb, p_Cr = pixel   # Pixel components\n",
    "        return abs(Y - p_Y) + abs(Cb - p_Cb) + abs(Cr - p_Cr)\n",
    "\n",
    "    def update_weights(self, weights, matched_index):\n",
    "        \"\"\"Update weights.\"\"\"\n",
    "        for k in range(len(weights)):\n",
    "            if k == matched_index:\n",
    "                weights[k] += (1 / self.L) * (1 - weights[k])\n",
    "            else:\n",
    "                weights[k] += (1 / self.L) * (0 - weights[k])\n",
    "\n",
    "    def normalize_weights(self, weights):\n",
    "        \"\"\"Normalize weights to sum to 1.\"\"\"\n",
    "        total = np.sum(weights)\n",
    "        return weights / total if total > 0 else weights\n",
    "\n",
    "    def adapt_centroid(self, centroid, pixel):\n",
    "        \"\"\"Adapt the centroid towards the incoming pixel.\"\"\"\n",
    "        error = centroid[1:] - pixel\n",
    "        overflow = error > self.L - 1\n",
    "        underflow = error < -self.L\n",
    "        adjustment = np.where(overflow, -1, np.where(underflow, 1, 0))\n",
    "        centroid[1:] += adjustment\n",
    "\n",
    "    def classify_pixel(self, cluster_weights, matched_index):\n",
    "        \"\"\"Classify a pixel as foreground or background.\"\"\"\n",
    "        P = np.sum(cluster_weights[matched_index + 1:])\n",
    "        return P\n",
    "\n",
    "    def process_frame(self, frame):\n",
    "        \"\"\"Process a single frame.\"\"\"\n",
    "        output = np.zeros((self.height, self.width), dtype=np.uint8)\n",
    "\n",
    "        for y in range(self.height):\n",
    "            for x in range(self.width):\n",
    "                pixel = frame[y, x]\n",
    "                cluster_group = self.clusters[y, x]\n",
    "\n",
    "                # Step 1: Cluster matching\n",
    "                distances = [\n",
    "                    self.manhattan_distance(cluster, pixel)\n",
    "                    for cluster in cluster_group\n",
    "                ]\n",
    "                matches = [i for i, d in enumerate(distances) if d <= self.manhattan_threshold]\n",
    "\n",
    "                if matches:\n",
    "                    # Matching cluster found\n",
    "                    matched_index = matches[0]\n",
    "                    self.adapt_centroid(cluster_group[matched_index], pixel)\n",
    "                    self.update_weights(cluster_group[:, 0], matched_index)\n",
    "                else:\n",
    "                    # No matching cluster found\n",
    "                    min_weight_index = np.argmin(cluster_group[:, 0])\n",
    "                    cluster_group[min_weight_index] = np.array([0.01, *pixel])\n",
    "\n",
    "                # Normalize weights\n",
    "                cluster_group[:, 0] = self.normalize_weights(cluster_group[:, 0])\n",
    "\n",
    "                # Sort clusters by weight\n",
    "                cluster_group = cluster_group[np.argsort(cluster_group[:, 0])[::-1]]\n",
    "\n",
    "                # Classification\n",
    "                P = self.classify_pixel(cluster_group[:, 0], matches[0] if matches else -1)\n",
    "                output[y, x] = 255 if P > 0.5 else 0  # Binary foreground/background\n",
    "\n",
    "                # Save back sorted clusters\n",
    "                self.clusters[y, x] = cluster_group\n",
    "\n",
    "        return output\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "29.612335318005833"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "def main():\n",
    "    # Open a video file or capture from a camera\n",
    "    cap = cv2.VideoCapture(r'C:\\Users\\muxia\\Desktop\\ece420final\\sample3.mp4')  # Replace 'video.mp4' with 0 for live camera\n",
    "\n",
    "    # Check if video capture is successful\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print(\"Failed to read video\")\n",
    "        exit()\n",
    "\n",
    "    # Define target dimensions\n",
    "    target_width = 320\n",
    "    target_height = 240\n",
    "\n",
    "    # Initialize BackgroundModel with resized frame dimensions\n",
    "    model = BackgroundModel(target_width, target_height)\n",
    "\n",
    "    # Create a directory to store the foreground images\n",
    "    output_dir = \"foreground_frames\"\n",
    "    if not os.path.exists(output_dir):\n",
    "        os.makedirs(output_dir)\n",
    "\n",
    "    frame_count = 0  # To track the frame number\n",
    "\n",
    "    while cap.isOpened():\n",
    "        ret, frame = cap.read()\n",
    "        if not ret:\n",
    "            break\n",
    "\n",
    "        # Resize the frame to 320x240\n",
    "        frame_resized = cv2.resize(frame, (target_width, target_height))\n",
    "\n",
    "        # Convert the resized frame to YCbCr format\n",
    "        frame_ycbcr = cv2.cvtColor(frame_resized, cv2.COLOR_BGR2YCrCb)\n",
    "\n",
    "        # Process frame\n",
    "        foreground = model.process_frame(frame_ycbcr)\n",
    "\n",
    "        # Save the foreground image to a file\n",
    "        output_path = os.path.join(output_dir, f\"foreground_{frame_count:04d}.png\")\n",
    "        cv2.imwrite(output_path, foreground)\n",
    "\n",
    "        print(f\"Saved foreground frame: {output_path}\")\n",
    "        frame_count += 1\n",
    "\n",
    "        # Break on 'q' key press (optional if running interactively)\n",
    "        if cv2.waitKey(30) & 0xFF == ord('q'):\n",
    "            break\n",
    "\n",
    "    cap.release()\n",
    "    print(\"Processing complete. Foreground frames saved.\")\n",
    "    \n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
